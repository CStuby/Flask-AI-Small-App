# Flask-AI-Small-App

A lightweight Flask web application that uses AI to answer common questions about Metropolia services. 
The app helps users get quick answers from a curated FAQ dataset by using Google Gemini 2.5 Flash to interpret the question and match it to known answers.
If the answer isnâ€™t available, the assistant responds politely and safely.

## ğŸš€ Features

- âœ” AI-powered FAQ assistant
- âœ” Uses Gemini 2.5 Flash for natural language understanding
- âœ” Prevents hallucinations using a controlled prompt
- âœ” Flask backend
- âœ” Simple HTML frontend
- âœ” Easy to extend with more FAQs

## ğŸ¯ Problem This Solves

Students may find information about:
- Course enrollment  
- Password resets  
- Schedules  
- IT services  

These answers are scattered across various platforms.  
This assistant centralizes the info and uses AI to respond in a user-friendly way.

## ğŸ“ Project Structure

```
Flask Small Coding App/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ faq_data.json
â”œâ”€â”€ requirements.txt
â”‚
â””â”€â”€ templates/
    â””â”€â”€ index.html
```

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/CStuby/Flask-AI-Small-App.git
   cd prototype-linkedin-future
   ```
2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
3. **Set your API key (Windows)**: 
   ```bash
   setx OPENAI_API_KEY "your_api_key_here"
   ```
4. **Run the app**:
   ```bash
   python app.py
   ```
5. **Open your browser at**:
   ```
   http://127.0.0.1:5000
   ```
## ğŸ§  How It Works

1. User enters a question

2. Flask sends the question plus the FAQ dataset to Gemini

3. Prompt engineering ensures the model:

    - Answers only from the dataset

    - Responds with a fallback message otherwise

4. The model returns the best answer

5. The UI displays it instantly

## ğŸ› ï¸ Tech Stack

- Python
- Flask
- HTML / Jinja2 templates
- OpenAI-compatible LLM API

## ğŸ“œ License

This project is for educational and demonstration purposes.
Feel free to modify it.
